<div class="hero-unit">
  <img class="pull-right" src="/image/tractor-500x320.png" width="220" height="141" alt="The ScraperWiki digger" style="margin: 0 0 10px 10px">
  <h1>Liberate your data <span style="opacity: 0.5">with ScraperWiki!</></h1>
  <p class="lead" style="margin-bottom: 0.5em">ScraperWiki helps you do data science on the&nbsp;web.</p>
  <p class="lead">Get, clean, analyse, visualise and manage your data,<br/>with&nbsp;simple tools or custom-written code.</p>
  <a class="btn btn-info" href="/professional/">ScraperWiki for businesses</a>
  <a class="btn btn-warning" href="/pricing/">Sign up <span class="muted">&ndash; Free</span></a>
</div>

<div id="use-cases">

  <ul>
    <li class="explore" data-section="explore"><img src="/image/use-case-excel.png" width="50" height="50" alt="">I usually explore data in Excel, but I want to take my data analysis to the next level.</li>
    <li class="datascience" data-section="datascience"><img src="/image/use-case-command.png" width="50" height="50" alt="">I want a place to write and run code that does awesome stuff with data.</li>
    <li class="professional" data-section="professional"><img src="/image/use-case-cash.png" width="59" height="50" alt="">I&rsquo;m a business and I need professional data extraction, analysis and management.</li>
  </ul>

  <section id="explore">
    <p class="lead">This section will contain:</p>
    <ul>
      <li>An explanation of what ScraperWiki is (datasets + tools)</li>
      <li>Mini case-studies of how you can combine tools for analysis</li>
      <li>A sign-up button (link to pricing page)</li>
    </ul>
  </section>

  <section id="datascience">
    <p class="lead">This section will contain:</p>
    <ul>
      <li>A technical description of how ScraperWiki tools work</li>
      <li>Mini case-studies of using tools for data science</li>
      <li>A sign-up button (link to pricing page)</li>
    </ul>
  </section>

  <section id="professional">
    <div id="process">
      <p class="lead">ScraperWiki is a place where data professionals get, clean, analyse, visualise and manage data</p>
      <p>ScraperWiki’s data scientists help customers collect data through automation, ask the right questions of their data, and analyse it forensically. They are experts at extracting value from external data, and combining it with internal datasets.</p>
      <p>Our data scientists bring a wealth of experience to each and every customer project. And our custom-built data hub keeps the process transparent and collaborative.</p>
      <p id="about-our-team"><a data-nonpushstate class="btn btn-warning" href="/about/">See more about our team</a></p>
    </div>

    <div id="customers">
      <img src="/image/logos.gif" width="1045" height="110" alt="Logos">
    </div>

    <div id="services">
      <h2>Our services include:</h2>
      <ul>
        <li><strong>Data subscriptions</strong> – regular scheduled custom data provision for a monthly fee with a setup charge. This might include pricing data, lead generation data, research data. Monitoring services for social media and websites. Market data collection.</li>
        <li><strong>Data hub</strong> - a collaborative platform for sharing, managing and analysing your data. This might be a standalone product where you carry out provision and analysis data yourselves, or a joint endeavour where we source and analyse data with you.</li>
        <li><strong>Data transformations</strong> – data collection at scale through scraping external or internal resources with transformation to formats for reuse.</li>
        <li><strong>Data sciences</strong> - analysis and visualisation of data, either acquired through scraping or ingested via more conventional means.</li>
        <li><strong>Data tools</strong> - The ScraperWiki platform includes ‘off the shelf’ data tools that our data services team use for customers.  In addition they can write customised data tools for specific projects.</li>
        <li><strong>Data workshops</strong> - sessions to help businesses understand methods in data collection, analysis and management.</li>
      </ul>
    </div>

    <div id="case-studies">
      <h2>Case studies</h2>
      <div class="carousel-wrapper">
        <div class="carousel">
          <div class="case-study">
            <a class="thumbnail" href="">
              <img src="/image/case-study-gov-uk.gif" width="1033" height="648" alt="gov.uk website">
            </a>
            <h3>UK Government Digital Services</h3>
            <p>When the government wanted to migrate its disparate departmental web sites to a unified central location, <a href="http://gov.uk">gov.uk</a>, they brought us in to carry out content scraping and transformation for upload to their new content management system.</p>
            <p>We delivered this work to a tight timeline, scraping dozens of sites and thousands of web pages. As a result of this work <a href="http://govstore.service.gov.uk/cloudstore/supplier/info/scraperwiki-ltd/">we are now suppliers on GCloud</a>.</p>
          </div>
          <div class="case-study">
            <a class="thumbnail" href="http://blog.scraperwiki.com/2011/03/08/600-lines-of-code-748-revisions-a-load-of-bubbles/">
              <img src="/image/case-study-bubbles.png" width="547" height="498" alt="Spending bubble visualisation">
            </a>
            <h3>Channel 4 Dispatches</h3>
            <p>When Channel 4&rsquo;s Dispatches program wished to investigate whether selling off Britain&rsquo;s assets could cut the national debt they turned to us to extract data from <a href="http://webarchive.nationalarchives.gov.uk/+/http://www.hm-treasury.gov.uk/psr_investment_nar_2007_index.htm">The National Asset Register 2007</a> which was locked up in PDF files.</p>
            <p>We created a sophisticated visualisation which enabled reporters and viewers to get an overview of the data with the ability to drill down to single lines in the original source documents.</p>
          </div>
          <div class="case-study">
            <a class="thumbnail" href="http://blog.scraperwiki.com/2011/03/08/600-lines-of-code-748-revisions-a-load-of-bubbles/">
              <img src="/image/case-study-brownfield.png" width="623" height="532" alt="Brownfield site visualisation">
            </a>
            <h3>Brownfield sites</h3>
            <p>As an extension of our work with Channel 4 Dispatches we were asked to help establish whether councils could sell 11,000 acres of land to fill budget holes. Our response was to create a visualisation tool where any viewer could type in a postcode to see available brownfield sites in their area.</p>
            <p>This visualisation was based on 25,000 data points stored in an Excel spreadsheet file, which we ingested into our data hub which provides richer analysis, visualisation and publication.</p>
          </div>
          <div class="case-study">
            <span class="thumbnail">
              <img src="/image/case-study-data-hub.jpg" width="920" height="560" alt="Corporate Data Hub screenshot">
            </span>
            <h3>Corporate data hub</h3>
            <p>A major business to business publisher has an ongoing need to source and share commodity pricing data amongst its journalists, and they find conventional mechanisms such as document management systems and shared drives lacking.</p>
            <p>The ScraperWiki data hub allows them to easily share data which they have sourced themselves and we are providing data using scrapers. The data hub also provides analysis and visualisation through an ever growing set of data tools. As part of our service we have delivered a Data 101 Workshop to their journalists and data professionals.</p>
          </div>
          <div class="case-study">
            <h3>Lead generation</h3>
            <p>A firm of lawyers in the US receives a &lsquo;Judgement Abstract Report&rsquo; as a PDF from the state every week. The report is used to identify potential clients for the law firm. It has a regular layout but it is not machine readable and reusing it once required manual retyping.</p>
            <p>We wrote a script which automatically receives the PDF, ingests it into their ScraperWiki datahub, schedules itself weekly to collect the incremental data, and makes the data available privately to the lawyers.</p>
          </div>
          <div class="case-study">
            <a class="thumbnail" href="https://ds-ec2.scraperwiki.com/edvno5y/8c908b4be29946c/http/#%7B%22source%22%3A%7B%22apikey%22%3A%22c2ece9db-9830-430b-bd32-9b5941b521ae%22%2C%22url%22%3A%22https%3A%2F%2Fds-ec2.scraperwiki.com%2Fedvno5y%2F8c908b4be29946c%22%2C%22publishToken%22%3A%228c908b4be29946c%22%2C%22box%22%3A%22edvno5y%22%7D%7D">
              <img src="/image/case-study-health-map.jpg" width="1055" height="637" alt="Health Map visualisation">
            </a>
            <h3>Liverpool John Moores University health map</h3>
            <p>A research department at the University wanted to provide data to the emergency services to support their work. For example, identifying factors such as numbers of assaults near licensed premises and schools, or numbers of ambulance call outs to falls by local demographics.</p>
            <p>For this work we matched up public data from the Office of National Statistics and local authorities with internal data from the emergency services. This data was then displayed on an interactive map which enabled researchers to make sense of the complex interactions in the data.</p>
            <p>You can see a <a href="https://box.scraperwiki.com/scraperwiki.health-map-demo/1486710f485b45d/http/">live version of this map</a> using simulated data here, with <a href="https://box.scraperwiki.com/scraperwiki.health-map-demo/1486710f485b45d/http/demo.mp4">a video walkthrough here</a>.</p>
          </div>
          <div class="case-study">
            <a class="thumbnail" href="https://ds-ec2.scraperwiki.com/am2xg4q/2c2d9b43fd9746f/http/#%7B%22source%22%3A%7B%22apikey%22%3A%22c2ece9db-9830-430b-bd32-9b5941b521ae%22%2C%22url%22%3A%22https%3A%2F%2Fds-ec2.scraperwiki.com%2Fam2xg4q%2F2c2d9b43fd9746f%22%2C%22publishToken%22%3A%222c2d9b43fd9746f%22%2C%22box%22%3A%22am2xg4q%22%2C%22sqlQuery%22%3Anull%7D%2C%22target%22%3A%7B%22url%22%3A%22https%3A%2F%2Fds-ec2.scraperwiki.com%2Ff2iy7si%2F1c21ceaaced2490%22%2C%22publishToken%22%3A%221c21ceaaced2490%22%2C%22box%22%3A%22f2iy7si%22%2C%22displayName%22%3A%22Somerset%20Fires%22%7D%7D">
              <img src="/image/case-study-rose.gif" width="1018" height="550" alt="Rose diagram showing accident callouts">
            </a>
            <h3>Devon and Somerset Fire Incident Data</h3>
            <p>As data scientists we are always eager to probe new and interesting data sources. One of our founders, Julian Todd, was interested in the <a href="http://www.dsfire.gov.uk/News/Newsdesk/IncidentsPast7days.cfm?siteCategoryId=3&T1ID=26&T2ID=35">Fire Incident Data</a> published by Devon &amp; Somerset&rsquo;s Fire and Rescue Service. The data is functionally and clearly presented, but it lacks the opportunity to see a bigger picture of how their resources are used and applied.</p>
            <p>By ingesting the data into the ScraperWiki data hub, and combining this with a sophisticated interactive visualisation, we are able to make much more of the underlying data.</p>
          </div>
          <div class="case-study">
            <h3>EU NewsReader Project (FP7)</h3>
            <p>We are working with academic groups and companies in a pan-European collaboration under the EU&rsquo;s Framework 7 research and innovation programme. The <a href="http://www.newsreader-project.eu/">NewsReader project</a> ingests vast quantities of news and related data and uses natural language processing to offer enhanced navigation and analysis.</p>
            <p>Our role is to provide data sources in the form of scrapers for openly available material such as parliamentary proceedings and to support the exploitation and dissemination of results and technologies arising from the project.</p>
          </div>
        </div>
      </div>
    </div>

    <div id="request">
      <h2>Get in touch</h2>
      <p>Our data scientists are ready to help you make the most of your data. Let&rsquo;s discuss where to start&nbsp;</p>
      <div class="medium" id="phone">
        <h4>Call us on:</h4>
        <a href="tel:00441513315200">+44 (0)151 3315200</a>
      </div>
      <div class="medium" id="email">
        <h4>Email us at:</h4>
        <a href="mailto:dataservices@scraperwiki.com">dataservices@scraperwiki.com</a>
      </div>
      <div class="medium" id="callback">
        <h4>Or request a call-back:</h4>
        <form action="" method="post">
          <div class="question name ">
            <p><label for="id_name">Your Name:</label>
            <input type="text" name="name" id="id_name"></p>
          </div>
          <div class="question phone ">
            <p><label for="id_phone">Your Phone or Skype:</label>
            <input type="text" name="phone" id="id_phone"></p>
          </div>
          <div class="question email ">
            <p><label for="id_email">Your Email address:</label>
            <input type="text" name="email" id="id_email"></p>
          </div>
          <div class="question description">
            <p><label for="id_description">Project brief: (optional)</label>
            <textarea id="id_description" rows="10" cols="40" name="description"></textarea></p>
          </div>
          <div class="last">
            <input type="submit" value="Call me back" class="btn btn-success">
          </div>
        </form>
      </div>
    </div>

    <div id="faq">
      <h2>FAQ</h2>
      <h3><i class="icon-chevron-right"></i> How do I request your services?</h3>
      <p>We ask you to complete our simple form [link] to give your contact details and provide a brief summary of your requirements. This will generate a unique identifier which we will use to track your request through our systems.</p>
      <h3><i class="icon-chevron-right"></i> What information do I need to provide?</h3>
      <p>We will discuss your requirements with you but as a guide we would need you to provide a short brief for the project and a link to the data you wish us to work on, either as a URL or sample files. We would need a precise description of what data fields you require to be extracted from the source files, and the frequency with which you want the data to be collected. It also helpful to know your expectations for a delivery date.</p>
      <h3><i class="icon-chevron-right"></i> Can you give me some indication of cost?</h3>
      <p>The setup cost for a data feed or a one off data transformation project will be in the order of $3000&ndash;$10000 (€3000&ndash;€10000) although the upper end of this scale will depend on how much work is involved. To maintain an ongoing data feed will cost in the region of $200&ndash;$500 (€200&ndash;€500) per month.</p>
      <h3><i class="icon-chevron-right"></i> What&rsquo;s your process for managing service requests?</h3>
      <p>Typically the first stage of the process will be a discussion with one of our technical marketing team. For particularly complex requests this may involve one of our data scientists. The next stage in the process will be for us to conduct a detailed investigation, typically taking one of our data scientists half a day and often but not always resulting in the production of a sample dataset. There is a nominal charge of $300 (€300) for this investigation. Following this we will either proceed to the production phase, upon your approval or if the project has a significant level of risk we may propose a feasibility study.</p>
      <h3><i class="icon-chevron-right"></i> Do you have a service level agreement (SLA)?</h3>
      <p>Yes, we understand the requirements that our corporate customers will have and provide SLAs to suit those needs, at different price points.</p>
    </div>

    <div class="clearfix"></div>

  </section>

</div>

<div id="more-links" class="row-fluid">
  <a class="span6" href="/about">
    <h3>About us</h3>
    <p>Find out more about ScraperWiki and the people behind it.</p>
  </a>
  <a class="span6" href="/help">
    <h3>Help and documentation</h3>
    <p>See what's new in the beta, try our quick start guides and read the developer docs.</p>
  </a>
</div>
