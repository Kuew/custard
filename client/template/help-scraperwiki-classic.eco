<nav class="well">
  <ul class="nav nav-list">
    <li class="nav-header">Topics:</li>
    <li class="active"><a data-nonpushstate href="#what">What is happening?</a></li>
    <li><a data-nonpushstate href="#why">Why are you changing?</a></li>
    <li><a data-nonpushstate href="#migration">How do I migrate my Classic scrapers?</a></li>
    <li><a data-nonpushstate href="#how-about-no">What if I don&rsquo;t want to migrate my account?</a></li>
    <li><a data-nonpushstate href="#open-data">How do I open up my code and data?</a></li>
    <li><a data-nonpushstate href="#pricing">What happened to your unlimited free account?</a></li>
  </ul>
</nav>

<div class="wrapper">

  <div class="hero-classic">
    <img src="/image/classic-test-card.png" width="140" height="90" alt="">
    <h1>Confused about Classic and the new ScraperWiki?</h1>
    <p class="lead">We want to help everyone make the most of their data. And that includes ScraperWiki Classic users. How&nbsp;can&nbsp;we&nbsp;help?</p>
  </div>

  <h2 id="what">What is happening?</h2>

  <p>Since 2009, ScraperWiki has helped businesses and individuals liberate data on the web. Originally that required you to write code. But in 2013, we rewrote our platform from the ground up, to bring you point-and-click tools for getting data from <a href="https://scraperwiki.com/tools/twitter">Twitter</a>, <a href="https://scraperwiki.com/tools/tablextract">PDFs</a> and lots more.</p>

  <p>Running both the old &ldquo;Classic&rdquo; platform and the new one, side-by-side, was never going to be a viable solution. So we&rsquo;ve worked out a gentle retirement plan that lets ScraperWiki Classic users migrate their code to our new platform, or to a third-party code hosting service, whenever they&rsquo;re ready.</p>

  <p><b>On 12th March 2014</b>, scrapers on ScraperWiki Classic will become read-only. And <b>on 17th March</b>, scheduled scrapers will stop running.</p>

  <p>From then onwards, the code and data of all ScraperWiki Classic scrapers will remain available at <a href="https://classic.scraperwiki.com">classic.scraperwiki.com</a>, in a read-only form.</p>

  <p>We&rsquo;ve partnered with <a href="https://www.openaustraliafoundation.org.au">OpenAustralia</a> to make migrating to their <a href="https://morph.io">new Morph.io service</a> as easy as possible, and you&rsquo;ll still be able to do that, even after the 17th March.</p>

  <p>We also, of course, have an <a href="https://scraperwiki.com/tools/code-in-browser/">online scraper editor</a> on the new platform, and if you&rsquo;re a journalist, you&rsquo;re welcome to get a <a href="https://scraperwiki.com/journalists">free upgrade to a 20-dataset plan</a>.</p>

  <hr/>

  <h2 id="why">Why are you changing?</h2>

  <p>We&rsquo;ve changed in order to make ScraperWiki both simpler and more powerful.</p>

  <p><strong>Simpler</strong> for end-users through a <a href="http://blog.scraperwiki.com/2013/07/03/announcing-the-new-scraperwiki-com/">whole ecosystem of tools</a> that let them get, clean and analyse data without needing a single line of code. And <strong>more powerful</strong> for programmers through an <a href="http://blog.scraperwiki.com/2013/05/30/10-technical-things-you-didnt-know-about-the-new-scraperwiki/">industry-standard development environment</a> that works with all your usual software practices like Git, SSH and Cron.</p>

  <p>You can still <a href="https://scraperwiki.com/help/code-in-your-browser/">write web scrapers in your browser</a> and <a href="http://groups.google.com/group/ScraperWiki">our mailing list</a> is still a great place to get help with your programming roadbumps. But tools on the new ScraperWiki can go much further than that, and we look forward to releasing more and more as time goes on.</p>

  <hr/>

  <h2 id="migration">How do I migrate my Classic scrapers?</h2>

  <p>You should first <a href="https://scraperwiki.com/pricing">sign up to the new ScraperWiki</a> (you will <em>not</em> simply be able to log in with your Classic details â€“ the two products are entirely separate, and you&rsquo;ll need a new account on the new site).</p>

  <p>Once you&rsquo;ve verified your account, click <strong>Create a new dataset</strong> on the homepage, and then pick the <strong>Code in your browser</strong> tool. You&rsquo;ll be taken to an editor window you might recognise from ScraperWiki Classic!</p>

  <p>If you don&rsquo;t care about copying your old data from ScraperWiki Classic, you can just copy your old scraper source code and then paste it into this new <strong>Code in your browser</strong> window. Make sure to add a &ldquo;hashbang&rdquo; line at the top, like this <code>#!/usr/bin/env python</code> substituting <code>python</code> for <code>ruby</code> or <code>php</code> if neccessary.</p>

  <p>If you <em>do want</em> to migrate all your old data along with the code from Classic, we suggest you try a migration script like <a href="http://rdjcode.wordpress.com/2013/07/03/moving-from-scraperwiki-classic-to-scraperwiki-awesome/">the one Ross Jones voluntarily wrote</a>.</p>

  <hr/>

  <h2 id="how-about-no">What if I don&rsquo;t want to migrate my account?</h2>

  <p>No problem! Your code and data will remain available in a read-only form on <a href="https://classic.scraperwiki.com">classic.scraperwiki.com</a> for as long as we&rsquo;re able to keep it.</p>

  <p>If you want to write your own backup script, the code for every public scraper can be downloaded by visiting a URL like this:</p>

  <pre>https://classic.scraperwiki.com/editor/raw/<strong>your_scraper_name_here</strong></pre>

  <p>Likewise, you can download a scraper&rsquo;s SQLite database using a URL like this:</p>

  <pre>https://classic.scraperwiki.com/scrapers/export_sqlite/<strong>your_scraper_name_here</strong></pre>

  <p>There&rsquo;s also <a href="http://rdjcode.wordpress.com/2013/07/03/backing-up-all-your-scraperwiki-data/">a handy script</a> that will automate the backup process for you.</p>

  <hr/>

  <h2 id="open-data">How do I open up my code and data?</h2>

  <p>Sharing code and data is pretty well covered by services like Github, BitBucket and CKAN. So rather than competing, we want to integrate with these external services, so you can share your content just like everyone else.</p>

  <p>For sharing data from ScraperWiki, we&rsquo;ve released an <a href="https://blog.scraperwiki.com/2013/07/open-your-data-with-scraperwiki/">&ldquo;Open your data&rdquo; tool</a> that publishes your ScraperWiki datasets to public open data catalogues like <a href="http://datahub.io">datahub.io</a>. We&rsquo;re also working on an OData tool that&rsquo;ll let you easily export your data to tools like <a href="http://www.tableausoftware.com/about/blog/2013/11/build-simple-twitter-tracker-using-our-template-27252">Tableau Public</a>.</p>

  <p>If you have code on ScraperWiki Classic that you&rsquo;d like to share and work on in public, we suggest you <a href="https://blog.scraperwiki.com/2014/03/scraperwiki-classic-retirement-guide">migrate your scraper to Morph.io</a> using the buttons on every ScraperWiki Classic page.</p>

  <p>If you have code on the <i>new</i> ScraperWiki, and you want to share it, try pushing it into a version control service like <a href="http://github.com">Github</a>, <a href="http://bitbucket.org">BitBucket</a> or <a href="http://gitorious.org">Gitorious</a> via SSH.</p>

  <hr/>

  <h2 id="pricing">What happened to your unlimited free account?</h2>

  <p>We knew from the outset that ScraperWiki Classic&rsquo;s pricing model wouldn&rsquo;t work for our new platform, especially since you now get many of the &lsquo;premium&rsquo; features from Classic, like hourly scheduling and private code, for free.</p>

  <p>Yet we didn&rsquo;t want to go paid-only, since that would make it difficult for people to try us out, or to use ScraperWiki for their own small-scale personal projects.</p>

  <p>The 3 dataset limit was based on people&rsquo;s predominant usage of ScraperWiki Classic &ndash; it should give you plenty of room to try ScraperWiki out before you upgrade to one of our paid accounts. If you need more than that, and you&rsquo;re working on a serious open data project, <a href="/contact" data-nonpushstate>contact us</a>, and we&rsquo;ll upgrade you for free. We also offer a <a href="https://scraperwiki.com/journalists">free 20-dataset plan for Journalists</a>.</p>

</div>
